{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>AI in Fact and Fiction - Summer 2021</h1>\n",
    "<h2>Introduction to Deep Learning and PyTorch Basics</h2>\n",
    "\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In this lab, you will learn the basics of PyTorch. You will learn about tensors, compare them to vectors, and NumPy arrays, learn the basics of tensor operations on 1D and 2D tensors, learn how to do differentiation in PyTorch, and learn about the Dataset class.</p>\n",
    "<p>You will also learn about the building blocks of deep learning, and explore some basic ideas in Linear Regression and Gradient Descent.</p>\n",
    "\n",
    "* Use [Google Collab](https://colab.research.google.com/github/AIFictionFact/Summer2021/blob/master/lab1.ipynb) to run the python code, and to complete any missing lines of code.\n",
    "* You might find it helpful to save this notebook on your Google Drive.\n",
    "* Please make sure to fill the required information in the **Declaration** cell.\n",
    "* Once you complete the lab, please download the .ipynb file (File --> Download .ipynb).\n",
    "* Then, please use the following file naming convention to rename the downloaded python file lab1_YourRCS.ipynb (make sure to replace 'YourRCS' with your RCS ID, for example 'lab1_senevo.ipynb').\n",
    "* Submit the .ipynb file in LMS.\n",
    "\n",
    "<p>Due Date/Time: Friday, Jun 18 <b>1.00 PM ET</b></p>\n",
    "\n",
    "<p>Estimated Time Needed: <b>4 hours</b></p>\n",
    "\n",
    "<p>Total Tasks: <b>21</b></p>\n",
    "<p>Total Points: <b>50</b></p>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "source": [
    "\n",
    "**Declaration**\n",
    "\n",
    "*Your Name* :\n",
    "\n",
    "*Collaborators (if any)* :\n",
    "\n",
    "*Online Resources consulted (if any):*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preparation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the following libraries that you'll use for this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "source": [
    "(By the way, `%matplotlib inline` ensures that all matplotlib plots will be plotted in the output cell within the notebook and will be kept in the notebook when saved. This type of code is called \"line magics\" and are functions that you can run on cells. They should be at the beginning of a line and take as an argument the rest of the line from where they are called.)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plotVec function is a helper function for plotting diagrams. You will use this function to plot the vectors in a coordinate system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotVec(vectors):\n",
    "    \"\"\" Plot vecotrs, please keep the parameters in the same length\n",
    "    @param: vectors = [{\"vector\": vector variable, \"name\": name of vector, \"color\": color of the vector on diagram}]\n",
    "    \"\"\"\n",
    "    ax = plt.axes()\n",
    "    # For loop to draw the vectors\n",
    "    for vec in vectors:\n",
    "        ax.arrow(0, 0, *vec[\"vector\"], head_width = 0.05,color = vec[\"color\"], head_length = 0.1)\n",
    "        plt.text(*(vec[\"vector\"] + 0.1), vec[\"name\"])\n",
    "    plt.ylim(-2,2)\n",
    "    plt.xlim(-2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Types_Shape\">Types and Shape of 1-D tensors</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the type of the following list of integers <i>[0, 1, 2, 3, 4]</i> by applying the method <code>torch.tensor()</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert an integer list with length 5 to a tensor.\n",
    "# Then examine the type of the objects contained in the tensor, and the type of the tensor itself.\n",
    "ints = [0, 1, 2, 3, 4]\n",
    "ints_to_tensor = torch.tensor(ints)\n",
    "print(\"The dtype of tensor object after converting it to tensor: \", ints_to_tensor.dtype)\n",
    "print(\"The type of tensor object after converting it to tensor: \", ints_to_tensor.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the type of this float list <i>[0.0, 1.0, 2.0, 3.0, 4.0]</i> by applying the method <code>torch.tensor()</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a float list with length 5 to a tensor\n",
    "floats = [0.0, 1.0, 2.0, 3.0, 4.0]\n",
    "floats_to_tensor = torch.tensor(floats)\n",
    "print(\"The dtype of tensor object after converting it to tensor: \", floats_to_tensor.dtype)\n",
    "print(\"The type of tensor object after converting it to tensor: \", floats_to_tensor.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The float list is converted to a float tensor.</p>\n",
    "<b>Note: The elements in the list that will be converted to tensor must have the same type.</b>\n",
    "<p>From the previous examples, you see that <code>torch.tensor()</code> converts the list to the tensor type, which is similar to the original list type. However, what if you want to convert the list to a certain tensor type? <code>torch</code> contains the methods required to do this conversion. The following code  converts an integer list to float tensor:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a integer list with length 5 to float tensor\n",
    "new_float_tensor = torch.FloatTensor(ints)\n",
    "print(\"The type of the new_float_tensor:\", new_float_tensor.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You can also convert an existing tensor object (<code><i>tensor_obj</i></code>) to another tensor type. Convert the integer tensor to a float tensor:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another method to convert the integer list to float tensor\n",
    "old_int_tensor = torch.tensor(ints)\n",
    "new_float_tensor = old_int_tensor.type(torch.FloatTensor)\n",
    "print(\"The type of the new_float_tensor:\", new_float_tensor.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The <code><i>tensor_obj</i>.size()</code> helps you to find out the size of the <code><i>tensor_obj</i></code>.\n",
    "The <code><i>tensor_obj</i>.ndimension()</code> shows the dimension of the tensor object.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce the tensor_obj.size() & tensor_ndimension.size() methods\n",
    "\n",
    "print(\"The size of the new_float_tensor: \", new_float_tensor.size())\n",
    "print(\"The dimension of the new_float_tensor: \",new_float_tensor.ndimension())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The <code><i>tensor_obj</i>.view(<i>row, column</i>)</code> is used for reshaping a tensor object.<br></p>\n",
    "<p>What if you have a tensor object with <code>torch.Size([5])</code> as a <code>new_float_tensor</code> as shown in the previous example?<br>\n",
    "After you execute <code>new_float_tensor.view(5, 1)</code>, the size of <code>new_float_tensor</code> will be <code>torch.Size([5, 1])</code>.<br>\n",
    "This means that the tensor object <code>new_float_tensor</code> has been reshaped from a one-dimensional  tensor object with 5 elements to a two-dimensional tensor object with 5 rows and 1 column.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce the tensor_obj.view(row, column) method\n",
    "twoD_float_tensor = new_float_tensor.view(5, 1)\n",
    "print(\"Original Size: \", new_float_tensor)\n",
    "print(\"Size after view method\", twoD_float_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Note that the original size is 5. The tensor after reshaping becomes a 5X1 tensor analog to a column vector.</p>\n",
    "<b>Note: The number of elements in a tensor must remain constant after applying view.</b>\n",
    "<p>What if you have a tensor with dynamic size but you want to reshape it? You can use <b>-1</b> to do just that.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce the use of -1 in tensor_obj.view(row, column) method\n",
    "twoD_float_tensor = new_float_tensor.view(-1, 1)\n",
    "print(\"Original Size: \", new_float_tensor)\n",
    "print(\"Size after view method\", twoD_float_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You get the same result as the previous example. The <b>-1</b> can represent any size. However, be careful because you can set only one argument as <b>-1</b>.</p>\n",
    "<p>You can also convert a <b>numpy</b> array to a <b>tensor</b>, for example: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a numpy array to a tensor\n",
    "\n",
    "numpy_array = np.array(floats)\n",
    "new_tensor = torch.from_numpy(numpy_array)\n",
    "\n",
    "print(\"The dtype of new tensor: \", new_tensor.dtype)\n",
    "print(\"The type of new tensor: \", new_tensor.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Converting a <b>tensor</b> to a <b>numpy</b> is also supported in PyTorch. The syntax is shown below:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a tensor to a numpy array\n",
    "\n",
    "back_to_numpy = new_tensor.numpy()\n",
    "print(\"The numpy array from tensor: \", back_to_numpy)\n",
    "print(\"The dtype of numpy array: \", back_to_numpy.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><code>back_to_numpy</code> and <code>new_tensor</code> still point to <code>numpy_array</code>. As a result, if we change <code>numpy_array</code> both <code>back_to_numpy</code> and <code>new_tensor</code> will change. For example if we set all the elements in <code>numpy_array</code> to zeros, <code>back_to_numpy</code> and <code> new_tensor</code> will follow suit.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all elements in numpy array to zero \n",
    "numpy_array[:] = 0\n",
    "print(\"The new tensor points to numpy_array : \", new_tensor)\n",
    "print(\"and back to numpy array points to the tensor: \", back_to_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Pandas Series</b>, a one-dimensional labeled array capable of holding data of any type (integer, string, float, python objects, etc.), can also be converted by using the numpy array that is stored in <code>pandas_series.values</code>. Note that <code>pandas_series</code> can be any pandas_series object. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a panda series to a tensor\n",
    "pandas_series=pd.Series([0.1, 2, 0.3, 10.1])\n",
    "new_tensor=torch.from_numpy(pandas_series.values)\n",
    "print(\"The new tensor from numpy array: \", new_tensor)\n",
    "print(\"The dtype of new tensor: \", new_tensor.dtype)\n",
    "print(\"The type of new tensor: \", new_tensor.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 1 (1 point)</h3>\n",
    "<p>Convert <code>your_tensor</code> to a 1X5 tensor.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the following tensor to a tensor object with 1 row and 5 columns\n",
    "your_tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Index_Slice\">Indexing and Slicing of 1-D tensors</h2>\n",
    "<p>In Python, <b>the index starts with 0</b>. Therefore, the last index will always be 1 less than the length of the tensor object.\n",
    "You can access the value on a certain index by using the square bracket, for example:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tensor for showing how the indexs work on tensors\n",
    "\n",
    "index_tensor = torch.tensor([0, 1, 2, 3, 4])\n",
    "print(\"The value on index 0:\",index_tensor[0])\n",
    "print(\"The value on index 1:\",index_tensor[1])\n",
    "print(\"The value on index 2:\",index_tensor[2])\n",
    "print(\"The value on index 3:\",index_tensor[3])\n",
    "print(\"The value on index 4:\",index_tensor[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now, you'll see how to change the values on certain indexes.</p>\n",
    "<p>Suppose you have a tensor as shown here: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tensor for showing how to change value according to the index\n",
    "\n",
    "tensor_sample = torch.tensor([20, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Assign the value on index 0 as 100:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the value on the index 0 to 100\n",
    "\n",
    "print(\"Inital value on index 0:\", tensor_sample[0])\n",
    "tensor_sample[0] = 100\n",
    "print(\"Modified tensor:\", tensor_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As you can see, the value on index 0 changes. Change the value on index 4 to 0:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the value on the index 4 to 0\n",
    "\n",
    "print(\"Inital value on index 4:\", tensor_sample[4])\n",
    "tensor_sample[4] = 0\n",
    "print(\"Modified tensor:\", tensor_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Next, let's get a subset of <code>tensor_sample</code>. The subset should contain the values in <code>tensor_sample</code> from index 1 to index 3.</p>\n",
    "<p><b>Note: The number on the left side of the colon represents the index of the first value. The number on the right side of the colon is always 1 larger than the index of the last value. For example, <code>tensor_sample[1:4]</code> means you get values from the index 1 to index 3 <i>(4-1)</i></b>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice tensor_sample\n",
    "\n",
    "subset_tensor_sample = tensor_sample[1:4]\n",
    "print(\"Original tensor sample: \", tensor_sample)\n",
    "print(\"The subset of tensor sample:\", subset_tensor_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for assigning values to the certain index, you can also assign the value to the slices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the values of <code>tensor_sample</code> from index 3 to index 4 to something else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the values on index 3 and index 4\n",
    "\n",
    "print(\"Inital value on index 3 and index 4:\", tensor_sample[3:5])\n",
    "tensor_sample[3:5] = torch.tensor([300.0, 400.0])\n",
    "print(\"Modified tensor:\", tensor_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use a variable to contain the selected indexes and pass that variable to a tensor slice operation as a parameter, for example:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using variable to contain the selected index, and pass it to slice operation\n",
    "\n",
    "selected_indexes = [3, 4]\n",
    "subset_tensor_sample = tensor_sample[selected_indexes]\n",
    "print(\"The inital tensor_sample\", tensor_sample)\n",
    "print(\"The subset of tensor_sample with the values on index 3 and 4: \", subset_tensor_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also assign one value to the selected indexes by using the variable. For example, assign 100,000 to all the <code>selected_indexes</code>: (<b>Note: You can use only one value for the assignment.</b>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using variable to assign the value to the selected indexes\n",
    "\n",
    "print(\"The inital tensor_sample\", tensor_sample)\n",
    "selected_indexes = [1, 3]\n",
    "tensor_sample[selected_indexes] = 100000\n",
    "print(\"Modified tensor with one value: \", tensor_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 2 (1 point)</h3>\n",
    "Change the values on index 3, index 4, and index 7 of the following tensor to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the values on index 3, 4, 7 to 0\n",
    "my_tensor = torch.tensor([2, 7, 3, 4, 6, 2, 3, 1, 2])\n",
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Tensor_Func\">Functions on 1-D tensors</h2>\n",
    "In this section, you'll work with some methods that you can apply to tensor objects.\n",
    "\n",
    "<h3>Mean and Standard Deviation</h3>\n",
    "You'll review the mean and standard deviation methods first. They are two basic statistical methods.\n",
    "<br/>\n",
    "Create a tensor with values <i>[1.0, -1, 1, -1]</i>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample tensor for mathmatic calculation methods on tensor\n",
    "\n",
    "math_tensor = torch.tensor([1.0, -1.0, 1, -1])\n",
    "print(\"Tensor example: \", math_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the mean method:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the mean for math_tensor\n",
    "\n",
    "mean = math_tensor.mean()\n",
    "print(\"The mean of math_tensor: \", mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation can also be calculated by using <code><i>tensor_obj</i>.std()</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the standard deviation for math_tensor\n",
    "\n",
    "standard_deviation = math_tensor.std()\n",
    "print(\"The standard deviation of math_tensor: \", standard_deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Max and Min</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you'll review another two useful methods: <code><i>tensor_obj</i>.max()</code> and <code><i>tensor_obj</i>.min()</code>. These two methods are used for finding the maximum value and the minimum value in the tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a <code>max_min_tensor</code>: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample for introducing max and min methods\n",
    "\n",
    "max_min_tensor = torch.tensor([1, 1, 3, 5, 5])\n",
    "print(\"Tensor example: \", max_min_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note: There are two minimum numbers as 1 and two maximum numbers as 5 in the tensor. Can you guess how PyTorch is going to deal with the duplicates?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply <code><i>tensor_obj</i>.max()</code> on <code>max_min_tensor</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for finding the maximum value in the tensor\n",
    "\n",
    "max_val = max_min_tensor.max()\n",
    "print(\"Maximum number in the tensor: \", max_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use <code><i>tensor_obj</i>.min()</code> on <code>max_min_tensor</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for finding the minimum value in the tensor\n",
    "\n",
    "min_val = max_min_tensor.min()\n",
    "print(\"Minimum number in the tensor: \", min_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Sin</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tensor with 0, π/2 and π. Then, apply the sin function on the tensor. Notice here that the <code>sin()</code> is not a method of tensor object but is a function of torch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for calculating the sin result of each element in the tensor\n",
    "\n",
    "pi_tensor = torch.tensor([0, np.pi/2, np.pi])\n",
    "sin = torch.sin(pi_tensor)\n",
    "print(\"The sin result of pi_tensor: \", sin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resultant tensor <code>sin</code> contains the result of the <code>sin</code> function applied to each element in the <code>pi_tensor</code>.<br>\n",
    "This is different from the previous methods. For <code><i>tensor_obj</i>.mean()</code>, <code><i>tensor_obj</i>.std()</code>, <code><i>tensor_obj</i>.max()</code>, and <code><i>tensor_obj</i>.min()</code>, the result is a tensor with only one number because these are aggregate methods.<br>\n",
    "However, the <code>torch.sin()</code> is not. Therefore, the resultant tensors have the same length as the input tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create Tensor by <code>torch.linspace()</code></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful function for plotting mathematical functions is <code>torch.linspace()</code>. <code>torch.linspace()</code> returns evenly spaced numbers over a specified interval. You specify the starting point of the sequence and the ending point of the sequence. The parameter <code>steps</code> indicates the number of samples to generate. Now, you'll work with <code>steps = 5</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First try on using linspace to create tensor\n",
    "\n",
    "len_5_tensor = torch.linspace(-2, 2, steps = 5)\n",
    "print (\"First try on linspace\", len_5_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign <code>steps</code> with 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second try on using linspace to create tensor\n",
    "\n",
    "len_9_tensor = torch.linspace(-2, 2, steps = 9)\n",
    "print (\"Second try on linspace\", len_9_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use both <code>torch.linspace()</code> and <code>torch.sin()</code> to construct a tensor that contains the 100 sin result in range from 0 (0 degree) to 2π (360 degree): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the tensor within 0 to 360 degree\n",
    "\n",
    "pi_tensor = torch.linspace(0, 2*np.pi, 100)\n",
    "sin_result = torch.sin(pi_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the result to get a clearer picture. You must cast the tensor to a numpy array before plotting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sin_result\n",
    "\n",
    "plt.plot(pi_tensor.numpy(), sin_result.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 3 (2 points)</h3>\n",
    "<p>Construct a tensor with 100 steps in the range -π/2 to π/2. Print out the maximum and minimum number in the tensor. Then apply the hyperbolic sine function (<code>torch.sinh()</code>) to the tensor you created and plot the result using <code>plt.plot</code> method.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a tensor with 100 steps in the range -π/2 to π/2. Print out the maximum and minimum number. Then apply the hyperbolic sine function (torch.sinh())  to the tensor you created and plot the result.\n",
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Tensor_Op\">Tensor Operations on 1-D tensors</h2>\n",
    "In the following section, you'll work with operations that you can apply to a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tensor Addition</h3>\n",
    "You can perform addition between two tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a tensor <code>u</code> with 1 dimension and 2 elements, and another tensor <code>v</code> with the same number of dimensions and the same number of elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two sample tensors\n",
    "\n",
    "u = torch.tensor([1, 0])\n",
    "v = torch.tensor([0, 1])\n",
    "# Add u and v\n",
    "\n",
    "w = u + v\n",
    "print(\"The result tensor: \", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the result using the `plotVec(` method we defined earlier in the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot u, v, w\n",
    "\n",
    "plotVec([\n",
    "    {\"vector\": u.numpy(), \"name\": 'u', \"color\": 'r'},\n",
    "    {\"vector\": v.numpy(), \"name\": 'v', \"color\": 'b'},\n",
    "    {\"vector\": w.numpy(), \"name\": 'w', \"color\": 'g'}\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 4 (1 point)</h3> \n",
    "Implement the tensor subtraction with <code>u</code> and <code>v</code>, i.e., <code>u - v</code>, as w, print the result and plot it using the <code>plotVec</code> method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.tensor([1, 0])\n",
    "v = torch.tensor([0, 1])\n",
    "# Implement the tensor subtraction with u and v, print the result and plot it.\n",
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add a scalar to the tensor. Use <code>u</code> as the sample tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor + scalar\n",
    "\n",
    "u = torch.tensor([1, 2, 3, -1])\n",
    "v = u + 1\n",
    "print (\"Addition Result: \", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tensor Multiplication </h3>\n",
    "Now, you'll review the multiplication between a tensor and a scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tensor with value <code>[1, 2]</code> and then multiply it by 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor * scalar\n",
    "\n",
    "u = torch.tensor([1, 2])\n",
    "v = 2 * u\n",
    "print(\"The result of 2 * u: \", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is <code>tensor([2, 4])</code>, so the code <code>2 * u</code> multiplies each element in the tensor by 2. This is how you get the product between a vector or matrix and a scalar in linear algebra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use multiplication between two tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two tensors <code>u</code> and <code>v</code> and then multiply them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor * tensor\n",
    "\n",
    "u = torch.tensor([1, 2])\n",
    "v = torch.tensor([3, 2])\n",
    "w = u * v\n",
    "print (\"The result of u * v\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is simply <code>tensor([3, 4])</code>. This result is achieved by multiplying every element in <code>u</code> with the corresponding element in the same position <code>v</code>, which is similar to <i>[1 * 3, 2 * 2]</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dot Product</h3>\n",
    "The dot product is a special operation for a vector that you can use in Torch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the dot product of the two tensors <code>u</code> and <code>v</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate dot product of u, v\n",
    "\n",
    "u = torch.tensor([1, 2])\n",
    "v = torch.tensor([3, 2])\n",
    "\n",
    "print(\"Dot Product of u, v:\", torch.dot(u,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is <code>tensor(7)</code>. The function is <i>1 x 3 + 2 x 2 = 7</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 5 (1 point)</h3>\n",
    "\n",
    "Convert the lists <i>[-1, 1]</i> and <i>[1, 1]</i> to tensors <code>u</code> and <code>v</code>. Then, plot the tensor <code>u</code> and <code>v</code> as a vector by using the function <code>plotVec</code> and find the dot product as <code>w</code> and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the dot product of u and v, and plot out two vectors\n",
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Types_Shape\">Types and Shape of 2-D tensors</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how to convert a 2D list to a 2D tensor. First, let us create a 3X3 2D list. Then let us try to use <code>torch.tensor()</code> which we used for converting a 1D list to 1D tensor. Is it going to work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 2D List to 2D Tensor\n",
    "\n",
    "twoD_list = [[11, 12, 13], [21, 22, 23], [31, 32, 33]]\n",
    "twoD_tensor = torch.tensor(twoD_list)\n",
    "print(\"The New 2D Tensor: \", twoD_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try <code><i>tensor_obj</i>.ndimension()</code> (<code>tensor_obj</code>: This can be any tensor object), <code><i>tensor_obj</i>.shape</code>, and <code><i>tensor_obj</i>.size()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try tensor_obj.ndimension(), tensor_obj.shape, tensor_obj.size()\n",
    "\n",
    "print(\"The dimension of twoD_tensor: \", twoD_tensor.ndimension())\n",
    "print(\"The shape of twoD_tensor: \", twoD_tensor.shape)\n",
    "print(\"The shape of twoD_tensor: \", twoD_tensor.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us try converting the tensor to a numpy array and convert the numpy array back to a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tensor to numpy array; Convert numpy array to tensor\n",
    "\n",
    "twoD_numpy = twoD_tensor.numpy()\n",
    "print(\"Tensor -> Numpy Array:\")\n",
    "print(\"The numpy array after converting: \", twoD_numpy)\n",
    "print(\"Type after converting: \", twoD_numpy.dtype)\n",
    "\n",
    "print(\"================================================\")\n",
    "\n",
    "new_twoD_tensor = torch.from_numpy(twoD_numpy)\n",
    "print(\"Numpy Array -> Tensor:\")\n",
    "print(\"The tensor after converting:\", new_twoD_tensor)\n",
    "print(\"Type after converting: \", new_twoD_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us try to convert a Pandas Dataframe to a tensor. The process is the same as the 1D conversion. We can obtain the numpy array via the attribute <code>values</code>. Then, we can use <code>torch.from_numpy()</code> to convert the value of the Pandas Series to a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to convert the Panda Dataframe to tensor\n",
    "\n",
    "df = pd.DataFrame({'a':[11,21,31],'b':[12,22,312]})\n",
    "\n",
    "print(\"Pandas Dataframe to numpy: \", df.values)\n",
    "print(\"Type BEFORE converting: \", df.values.dtype)\n",
    "\n",
    "print(\"================================================\")\n",
    "\n",
    "new_tensor = torch.from_numpy(df.values)\n",
    "print(\"Tensor AFTER converting: \", new_tensor)\n",
    "print(\"Type AFTER converting: \", new_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 6 (1 point)</h3>\n",
    "Convert the following Pandas Dataframe  to a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Pandas Series to tensor\n",
    "df = pd.DataFrame({'A':[11, 33, 22],'B':[3, 3, 2]})\n",
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Index_Slice\">Indexing and Slicing of 2D-tensors</h2>\n",
    "You can use rectangular brackets to access the different elements of the tensor. Now, let us try to access the value on position 2nd-row 3rd-column. Remember that the index is always 1 less than how we count rows and columns. There are two ways to access the certain value of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tensor_obj[row, column] and tensor_obj[row][column] to access certain position\n",
    "\n",
    "tensor_example = torch.tensor([[11, 12, 13], [21, 22, 23], [31, 32, 33]])\n",
    "print(\"What is the value on 2nd-row 3rd-column? \", tensor_example[1, 2])\n",
    "print(\"What is the value on 2nd-row 3rd-column? \", tensor_example[1][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to get the value on both 1st-row 1st-column and 1st-row 2nd-column? You can also use slicing in a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tensor_obj[begin_row_number: end_row_number, begin_column_number: end_column number] \n",
    "# and tensor_obj[row][begin_column_number: end_column number] to do the slicing\n",
    "\n",
    "tensor_example = torch.tensor([[11, 12, 13], [21, 22, 23], [31, 32, 33]])\n",
    "print(\"What is the value on 1st-row first two columns? \", tensor_example[0, 0:2])\n",
    "print(\"What is the value on 1st-row first two columns? \", tensor_example[0][0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the result as <code>tensor([11, 12])</code> successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we <b>can't</b> combine using slicing on row and pick one column by using the code <code>tensor_obj[begin_row_number: end_row_number][begin_column_number: end_column number]</code>. The reason is that the slicing will be applied on the tensor first. The result type will be a two dimension again. The second bracket will no longer represent the index of the column it will be the index of the row at that time. Let us see an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give an idea on tensor_obj[number: number][number]\n",
    "\n",
    "tensor_example = torch.tensor([[11, 12, 13], [21, 22, 23], [31, 32, 33]])\n",
    "sliced_tensor_example = tensor_example[1:3]\n",
    "print(\"1. Slicing step on tensor_example: \")\n",
    "print(\"Result after tensor_example[1:3]: \", sliced_tensor_example)\n",
    "print(\"Dimension after tensor_example[1:3]: \", sliced_tensor_example.ndimension())\n",
    "print(\"================================================\")\n",
    "print(\"2. Pick an index on sliced_tensor_example: \")\n",
    "print(\"Result after sliced_tensor_example[1]: \", sliced_tensor_example[1])\n",
    "print(\"Dimension after sliced_tensor_example[1]: \", sliced_tensor_example[1].ndimension())\n",
    "print(\"================================================\")\n",
    "print(\"3. Combine these steps together:\")\n",
    "print(\"Result: \", tensor_example[1:3][1])\n",
    "print(\"Dimension: \", tensor_example[1:3][1].ndimension())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the results and dimensions in scenarios 2 and 3 above are the same. Both of them contain the 3rd row in the <code>tensor_example</code>, but not the last two values in the 3rd column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how can we get the elements in the 3rd column with the last two rows? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tensor_obj[begin_row_number: end_row_number, begin_column_number: end_column number] \n",
    "\n",
    "tensor_example = torch.tensor([[11, 12, 13], [21, 22, 23], [31, 32, 33]])\n",
    "print(\"What is the value on 3rd-column last two rows? \", tensor_example[1:3, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, the code <code>tensor_obj[begin_row_number: end_row_number, begin_column_number: end_column number]</code> still works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 7 (1 point)</h3>\n",
    "Change the values of the last two rows of the second column to 0. Basically, change the values on <code>tensor_ques[1][1]</code> and <code>tensor_ques[2][1]</code> to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use slice and index to change the values on the matrix tensor_ques.\n",
    "tensor_ques = torch.tensor([[11, 12, 13], [21, 22, 23], [31, 32, 33]])\n",
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Tensor_Op\">Operations on 2D-tensors</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tensor Addition</h3>\n",
    "You can add tensors; the process is identical to matrix addition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate [[1, 0], [0, 1]] + [[2, 1], [1, 2]]\n",
    "\n",
    "X = torch.tensor([[1, 0],[0, 1]]) \n",
    "Y = torch.tensor([[2, 1],[1, 2]])\n",
    "X_plus_Y = X + Y\n",
    "print(\"The result of X + Y: \", X_plus_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Scalar Multiplication </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplying a tensor by a scalar is identical to multiplying a matrix by a scaler. If you multiply the matrix <b>Y</b> by the scalar 2, you simply multiply every element in the matrix by 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 2 * [[2, 1], [1, 2]]\n",
    "\n",
    "Y = torch.tensor([[2, 1], [1, 2]]) \n",
    "two_Y = 2 * Y\n",
    "print(\"The result of 2Y: \", two_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Element-wise Product</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplication of two tensors corresponds to an element-wise product or Hadamard product.  Consider matrix the <b>X</b> and <b>Y</b> with the same size. The Hadamard product corresponds to multiplying each of the elements at the same position, that is, multiplying elements with the same color together. The result is a new matrix that is the same size as matrix <b>X</b> and <b>Y</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate [[1, 0], [0, 1]] * [[2, 1], [1, 2]]\n",
    "\n",
    "X = torch.tensor([[1, 0], [0, 1]])\n",
    "Y = torch.tensor([[2, 1], [1, 2]]) \n",
    "X_times_Y = X * Y\n",
    "print(\"The result of X * Y: \", X_times_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Matrix Multiplication </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply matrix multiplication to two tensors, if you have learned linear algebra, you should know that in the multiplication of two matrices order matters. This means if <i>X * Y</i> is valid, it does not mean <i>Y * X</i> is valid. The number of columns of the matrix on the left side of the multiplication sign must equal to the number of rows of the matrix on the right side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us create a tensor <code>A</code> with size 2X3. Then, let us create another tensor <code>B</code> with size 3X2. Since the number of columns of <code>A</code> is equal to the number of rows of <code>B</code>. We are able to perform the multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use <code>torch.mm()</code> for calculating the multiplication between tensors with different sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate [[0, 1, 1], [1, 0, 1]] * [[1, 1], [1, 1], [-1, 1]]\n",
    "\n",
    "A = torch.tensor([[0, 1, 1], [1, 0, 1]])\n",
    "B = torch.tensor([[1, 1], [1, 1], [-1, 1]])\n",
    "A_times_B = torch.mm(A,B)\n",
    "print(\"The result of A * B: \", A_times_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 8 (1 point)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two tensors: <code>X</code> should be a 2x3 matrix and <code>Y</code> should be a 3x4 matrix. Multiply <code>X</code> and <code>Y</code> and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two tensors: X should be a 2x3 matrix and Y should be a 3x4 matrix. Multiply <code>X</code> and <code>Y</code> and print the result.\n",
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Differentiation in PyTorch</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Derivative\">Derivatives</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the tensor <code>x</code> and set the parameter <code>requires_grad</code> to true because you are going to take the derivative of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor x\n",
    "\n",
    "x = torch.tensor(2.0, requires_grad = True)\n",
    "print(\"The tensor x: \", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let us create a tensor according to the equation $ y=x^2 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor y according to y = x^2\n",
    "\n",
    "y = x ** 2\n",
    "print(\"The result of y = x^2: \", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let us take the derivative with respect x at x = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the derivative and print out the derivative at the value x = 2\n",
    "\n",
    "y.backward()\n",
    "print(\"The derivative at x = 2: \", x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding lines perform the following operation: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\mathrm{dy(x)}}{\\mathrm{dx}}=2x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to calculate the derivative for a more complicated function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the y = x^2 + 2x + 1, then find the derivative \n",
    "\n",
    "x = torch.tensor(2.0, requires_grad = True)\n",
    "y = x ** 2 + 2 * x + 1\n",
    "print(\"The result of y = x^2 + 2x + 1: \", y)\n",
    "y.backward()\n",
    "print(\"The dervative at x = 2: \", x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function is in the following form:\n",
    "$y=x^{2}+2x+1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative is given by:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\mathrm{dy(x)}}{\\mathrm{dx}}=2x+2$\n",
    "\n",
    "$\\frac{\\mathrm{dy(x=2)}}{\\mathrm{dx}}=2(2)+2=6$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 9 (3 points)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the derivative of $ y = 2x^3+x $ at $x=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the derivative of y = 2x^3 + x at x = 1\n",
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Partial_Derivative\">Partial Derivatives</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate <b>Partial Derivatives</b>. Consider the function: $f(u,v)=vu+u^{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create <code>u</code> tensor, <code>v</code> tensor and  <code>f</code> tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate f(u, v) = v * u + u^2 at u = 1, v = 2\n",
    "\n",
    "u = torch.tensor(1.0,requires_grad=True)\n",
    "v = torch.tensor(2.0,requires_grad=True)\n",
    "f = u * v + u ** 2\n",
    "print(\"The result of v * u + u^2: \", f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equivalent to the following: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f(u=1,v=2)=(2)(1)+1^{2}=3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us take the derivative with respect to <code>u</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the derivative with respect to u\n",
    "\n",
    "f.backward()\n",
    "print(\"The partial derivative with respect to u: \", u.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the expression is given by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\mathrm{\\partial f(u,v)}}{\\partial {u}}=v+2u$\n",
    "\n",
    "$\\frac{\\mathrm{\\partial f(u=1,v=2)}}{\\partial {u}}=2+2(1)=4$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, take the derivative with respect to <code>v</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the derivative with respect to v\n",
    "\n",
    "print(\"The partial derivative with respect to u: \", v.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equation is given by:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\mathrm{\\partial f(u,v)}}{\\partial {v}}=u$\n",
    "\n",
    "$\\frac{\\mathrm{\\partial f(u=1,v=2)}}{\\partial {v}}=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the derivative with respect to a function with multiple values as follows. We can use the sum trick to produce a scalar valued function and then take the gradient: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the derivative with multiple values\n",
    "\n",
    "x = torch.linspace(-10, 10, 10, requires_grad = True)\n",
    "Y = x ** 2\n",
    "y = torch.sum(x ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the function  and its derivative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the derivative with respect to multiple value. Plot out the function and its derivative\n",
    "\n",
    "y.backward()\n",
    "\n",
    "plt.plot(x.detach().numpy(), Y.detach().numpy(), label = 'function')\n",
    "plt.plot(x.detach().numpy(), x.grad.numpy(), label = 'derivative')\n",
    "plt.xlabel('x')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The orange line is the slope of the blue line at the intersection point, which is the derivative of the blue line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>relu</b> activation function is an essential function in neural networks. We can take the derivative as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Take the derivative of Relu with respect to multiple value. Plot out the function and its derivative\n",
    "\n",
    "x = torch.linspace(-3, 3, 100, requires_grad = True)\n",
    "Y = F.relu(x)\n",
    "y = Y.sum()\n",
    "y.backward()\n",
    "plt.plot(x.detach().numpy(), Y.detach().numpy(), label = 'function')\n",
    "plt.plot(x.detach().numpy(), x.grad.numpy(), label = 'derivative')\n",
    "plt.xlabel('x')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 10 (3 points)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine partial derivative  $u$ of the following function where $u=2$ and $v=1$: $ f=uv+(uv)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the derivative of f = u * v + (u * v) ** 2 at u = 2, v = 1\n",
    "# Type the code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Simple Dataset</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the libraries we are going to use for this portion of the lab. The <code>torch.manual_seed()</code> is for forcing the random function in PyTorch to produce the same number every time we run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to create our own dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToySet(Dataset):\n",
    "    \"\"\"Toy Dataset Class\"\"\"\n",
    "    \n",
    "    def __init__(self, length = 100, transform = None):\n",
    "        \"\"\"Constructor with defult values \"\"\"\n",
    "        self.len = length\n",
    "        self.x = 2 * torch.ones(length, 2)\n",
    "        self.y = torch.ones(length, 1)\n",
    "        self.transform = transform\n",
    "     \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Getter\"\"\"\n",
    "        sample = self.x[index], self.y[index]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)     \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Get the number of items\"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us create our <code>ToySet</code> object, and find out the value on index 1 and the length of the inital dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset Object. \n",
    "# Find out the value on index 1. \n",
    "# Find out the length of Dataset Object.\n",
    "\n",
    "our_dataset = ToySet()\n",
    "print(\"Our ToySet object: \", our_dataset)\n",
    "print(\"Value on index 0 of our ToySet object: \", our_dataset[1])\n",
    "print(\"Our ToySet length: \", len(our_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply the same indexing convention as a <code>list</code>,\n",
    "and apply the function <code>len</code> on the <code>ToySet</code> object. We are able to customize the indexing and length method by <code>def &#95;&#95;getitem&#95;&#95;(self, index)</code> and <code>def &#95;&#95;len&#95;&#95;(self)</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us print out the first 3 elements and assign them to x and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use loop to print out first 3 elements in dataset\n",
    "for i in range(3):\n",
    "    x, y=our_dataset[i]\n",
    "    print(\"index: \", i, '; x:', x, '; y:', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 11 (1 point)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an <code>ToySet</code> object with length <b>50</b>. Print out the length of your object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new object with length 50, and print the length of object out.\n",
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Transforms\">Transforms</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create a class for transforming the data. In this case, we will try to add 1 to x and multiply y by 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddMult(object):\n",
    "    \"\"\"Transform class that adds to x and multiplies y by the given parameters.\"\"\"\n",
    "    \n",
    "    def __init__(self, addx = 1, muly = 2):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        self.addx = addx\n",
    "        self.muly = muly\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        \"\"\"Executor\"\"\"\n",
    "        x = sample[0]\n",
    "        y = sample[1]\n",
    "        x = x + self.addx\n",
    "        y = y * self.muly\n",
    "        sample = x, y\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a transform object:."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an AddMult transform object, and an ToySet object\n",
    "\n",
    "a_m = AddMult()\n",
    "data_set = ToySet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the outputs of the original dataset to <code>x</code> and <code>y</code>. Then, apply the transform <code>add_mult</code> to the dataset and output the values as <code>x_</code> and <code>y_</code>, respectively: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use loop to print out first 10 elements in dataset\n",
    "\n",
    "for i in range(10):\n",
    "    x, y = data_set[i]\n",
    "    print('Index: ', i, 'Original x: ', x, 'Original y: ', y)\n",
    "    x_, y_ = a_m(data_set[i])\n",
    "    print('Index: ', i, 'Transformed x_:', x_, 'Transformed y_:', y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the result, <code>x</code> has been added by 1 and y has been multiplied by 2, as <i>[2, 2] + 1 = [3, 3]</i> and <i>[1] x 2 = [2]</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply the transform object every time we create a new <code>ToySet object</code>. Remember, we have the constructor in ToySet class with the parameter <code>transform = None</code>.\n",
    "When we create a new object using the constructor, we can assign the transform object to the parameter transform, as the following code demonstrates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data_set object with AddMult object as transform\n",
    "\n",
    "cust_data_set = ToySet(transform = a_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This applied <code>a_m</code> object (a transform method) to every element in <code>cust_data_set</code> as initialized. Let us print out the first 10 elements in <code>cust_data_set</code> in order to see whether the <code>a_m</code> applied on <code>cust_data_set</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use loop to print out first 10 elements in dataset\n",
    "\n",
    "for i in range(10):\n",
    "    x, y = data_set[i]\n",
    "    print('Index: ', i, 'Original x: ', x, 'Original y: ', y)\n",
    "    x_, y_ = cust_data_set[i]\n",
    "    print('Index: ', i, 'Transformed x_:', x_, 'Transformed y_:', y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is the same as the previous method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 12 (4 points)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct your own <code>MyAddMult</code> class by adding x and y with 2 and then multiply both x and y by 10. Apply it on a new ToySet object, and print out the first 3 elements from the transformed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct your own MyAddMult transform by adding x and y with 2 and multiply both x and y by 10. \n",
    "# Apply MyAddMult on a new ToySet object. Print out the first three elements from the transformed dataset.\n",
    "# Type your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Compose\">Compose</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compose multiple transforms on the dataset object. First, import <code>transforms</code> from <code>torchvision</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the command below if you do not have torchvision installed\n",
    "# !pip install -y torchvision\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create a new transform class that multiplies each of the elements by 100: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mult(object):\n",
    "\n",
    "    def __init__(self, mult = 100):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        self.mult = mult\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        \"\"\"Executor\"\"\"\n",
    "        x = sample[0]\n",
    "        y = sample[1]\n",
    "        x = x * self.mult\n",
    "        y = y * self.mult\n",
    "        sample = x, y\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us try to combine the transforms <code>AddMult</code> and <code>Mult</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the AddMult() and Mult()\n",
    "\n",
    "data_transform = transforms.Compose([AddMult(), Mult()])\n",
    "print(\"The combination of transforms (Compose): \", data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new <code>Compose</code> object will perform each transform concurrently. Now we can pass the new <code>Compose</code> object (The combination of <code>AddMult()</code> and <code>Mult()</code>) to the constructor for creating <code>ToySet</code> object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new ToySet object with compose object as transform\n",
    "\n",
    "compose_data_set = ToySet(transform = data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us print out the first 3 elements in different <code>ToySet</code> datasets in order to compare the output after different transforms have been applied: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use loop to print out first 3 elements in dataset\n",
    "\n",
    "for i in range(3):\n",
    "    x, y = data_set[i]\n",
    "    print('Index: ', i, 'Original x: ', x, 'Original y: ', y)\n",
    "    x_, y_ = cust_data_set[i]\n",
    "    print('Index: ', i, 'Transformed x_:', x_, 'Transformed y_:', y_)\n",
    "    x_co, y_co = compose_data_set[i]\n",
    "    print('Index: ', i, 'Compose Transformed x_co: ', x_co ,'Compose Transformed y_co: ',y_co)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see what happened on index 0. The original value of <code>x</code> is <i>[2, 2]</i>, and the original value of <code>y</code> is [1]. If we only applied <code>AddMult()</code> on the original dataset, then the <code>x</code> became <i>[3, 3]</i> and y became <i>[2]</i>. Now let us see what is the value after applied both <code>AddMult()</code> and <code>Mult()</code>. The result of x is <i>[300, 300]</i> and y is <i>[200]</i>. The calculation which is equavalent to the compose is <i> x = ([2, 2] + 1) x 100 = [300, 300], y = ([1] x 2) x 100 = 200</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 13 (3 points)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the <code>Mult()</code> and <code>AddMult()</code> as <code>Mult()</code> to be executed first. And apply this on a new <code>ToySet</code> dataset. Print out the first 3 elements in the transformed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a compose as Mult() execute first and then AddMult(). Apply the compose on ToySet dataset. Print out the first 3 elements in the transformed dataset.\n",
    "# Type your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Prebuilt_Dataset\">Prebuilt Datasets</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will focus on the following libraries. Please note that the <code>torchvision</code> package consists of popular datasets, model architectures, and common image transformations for computer vision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can import a prebuilt dataset. In this case, we use <code>MNIST</code> (a database of handwritten digits). You'll work with several of these parameters later by placing a transform object in the argument <code>transform</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the prebuilt dataset into variable dataset\n",
    "\n",
    "dataset = dsets.MNIST(\n",
    "    root = './data', \n",
    "    train = False, \n",
    "    download = True, \n",
    "    transform = transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element of the dataset object contains a tuple. Let us see whether the first element in the dataset is a tuple and what is in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine whether the elements in dataset MNIST are tuples, and what is in the tuple?\n",
    "\n",
    "print(\"Type of the first element: \", type(dataset[0]))\n",
    "print(\"The length of the tuple: \", len(dataset[0]))\n",
    "print(\"The shape of the first element in the tuple: \", dataset[0][0].shape)\n",
    "print(\"The type of the first element in the tuple\", type(dataset[0][0]))\n",
    "print(\"The second element in the tuple: \", dataset[0][1])\n",
    "print(\"The type of the second element in the tuple: \", type(dataset[0][1]))\n",
    "print(\"As the result, the structure of the first element in the dataset is (tensor([1, 28, 28]), tensor(7)).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the output, the first element in the tuple is a cuboid tensor. As you can see, there is a dimension with only size 1, so basically, it is a rectangular tensor.<br>\n",
    "The second element in the tuple is a number tensor, which indicate the real number the image shows. As the second element in the tuple is <code>tensor(7)</code>, the image should show a hand-written 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper function for drawing diagram given a data sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showData(data_sample, shape = (28, 28)):\n",
    "    \"\"\"show data by diagram\n",
    "    \"\"\"\n",
    "    plt.imshow(data_sample[0].numpy().reshape(shape), cmap='gray')\n",
    "    plt.title('y = ' + str(data_sample[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the first element in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first element in the dataset\n",
    "showData(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the second sample:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the second element in the dataset\n",
    "showData(dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Torchvision\"> Torchvision Transforms  </h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply some image transform functions on the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, the images in the MNIST dataset can be cropped and converted to a tensor. We can use <code>transform.Compose</code> we learned from the previous section to combine the two transform functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine two transforms: crop and convert to tensor. Apply the compose to MNIST dataset\n",
    "\n",
    "croptensor_data_transform = transforms.Compose([transforms.CenterCrop(20), transforms.ToTensor()])\n",
    "dataset = dsets.MNIST(root = './data', train = False, download = True, transform = croptensor_data_transform)\n",
    "print(\"The shape of the first element in the first tuple: \", dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the image is now 20 x 20 instead of 28 x 28."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the first image again. You should notice that the image is cropped a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first element in the dataset\n",
    "showData(dataset[0],shape = (20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the second element in the dataset\n",
    "showData(dataset[1],shape = (20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below example, we horizontally flip the image, and then convert it to a tensor. Use <code>transforms.Compose()</code> to combine these two transform functions. Plot the flipped image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the compose. Apply it on MNIST dataset. Plot the image out.\n",
    "\n",
    "fliptensor_data_transform = transforms.Compose([transforms.RandomHorizontalFlip(p = 1),transforms.ToTensor()])\n",
    "dataset = dsets.MNIST(root = './data', train = False, download = True, transform = fliptensor_data_transform)\n",
    "showData(dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 14 (3 points)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the <code>RandomVerticalFlip</code> (vertically flip the image) with horizontally flip and convert to tensor as a compose. Apply the compose on image. Use <code>showData()</code> to plot the second image (the image has the hand-written digit <b>2</b>)."
   ]
  },
  {
   "source": [
    "# Combine vertical flip, horizontal flip and convert to tensor as a compose. Apply the compose on image. Then plot the image\n",
    "# Type your code here"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "<h2 id=\"lr-1d-prediction\">Linear Regression Prediction</h2>\n",
    "<p>In this section, we will see how to make a prediction in several different ways by using PyTorch.</h2>\n",
    "\n",
    "Let us create the following expressions:\n",
    "\n",
    "$b=-1,w=2$\n",
    "\n",
    "$\\hat{y}=-1+2x$\n",
    "\n",
    "First, let's define the parameters:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define w = 2 and b = -1 for y = wx + b\n",
    "w = torch.tensor(2.0, requires_grad = True)\n",
    "b = torch.tensor(-1.0, requires_grad = True)"
   ]
  },
  {
   "source": [
    "Then, define the function <code>forward(x)</code> to make the prediction: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    yhat = w * x + b\n",
    "    return yhat"
   ]
  },
  {
   "source": [
    "Let's make the following prediction at <i>x = 1</i>\n",
    "\n",
    "$\\hat{y}=-1+2x$\n",
    "\n",
    "$\\hat{y}=-1+2(1)$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict y = 2x - 1 at x = 1\n",
    "x = torch.tensor([[1.0]])\n",
    "yhat = forward(x)\n",
    "print(\"The prediction: \", yhat)"
   ]
  },
  {
   "source": [
    "Now, let us try to make the prediction for multiple inputs (i.e., <code>x</code> contains <code>1.0</code> and <code>2.0</code>). Let us construct the <code>x</code> tensor first. Let's check the shape of <code>x</code> first."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Create x Tensor and check the shape of x tensor\n",
    "x = torch.tensor([[1.0], [2.0]])\n",
    "print(\"The shape of x: \", x.shape)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "Now make the prediction: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the prediction of y = 2x - 1 at x = [1, 2]\n",
    "yhat = forward(x)\n",
    "print(\"The prediction: \", yhat)"
   ]
  },
  {
   "source": [
    "<h3 id=\"task-15\">Task 15 (3 points)</h3>\n",
    "Make a prediction of the following <code>x</code> tensor using the <code>w</code> and <code>b</code> from above. You must return the value from the <code>lab1_task15</code> function."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 15\n",
    "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
    "def lab1_task15(x):\n",
    "    # Type your code here to return the prediction"
   ]
  },
  {
   "source": [
    "<h3 id=\"Linear\">Class Linear</h3>\n",
    "\n",
    "We can also use the linear class to build more complex models. Let's first import the module."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear"
   ]
  },
  {
   "source": [
    "Set the random seed because the parameters are randomly initialized, otherwise. By seeding the random number generator to a fixed value the results will be reproducible."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "source": [
    "Let us create the linear object by using the constructor. The parameters are randomly created. Let us print out to see what <i>w</i> and <i>b</i> are."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Linear Regression Model, and print out the parameters\n",
    "linear = Linear(in_features=1, out_features=1, bias=True)\n",
    "print(\"Parameters w and b: \", list(linear.parameters()))"
   ]
  },
  {
   "source": [
    "This is equivalent to the following expression: \n",
    "\n",
    "$b=-0.4414, w=0.5153$\n",
    "\n",
    "$\\hat{y}=-0.4414+0.5153x$\n",
    "\n",
    "Now let us make a single prediction at <i>x = [[1.0]]</i>."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the prediction at x = [[1.0]]\n",
    "x = torch.tensor([[1.0]])\n",
    "yhat = linear(x)\n",
    "print(\"The prediction: \", yhat)"
   ]
  },
  {
   "source": [
    "Similarly, you can make multiple predictions for <code>x</code>. Use model <code>linear(x)</code> to predict the result."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prediction using linear model\n",
    "x = torch.tensor([[1.0], [2.0]])\n",
    "yhat = linear(x)\n",
    "print(\"The prediction: \", yhat)"
   ]
  },
  {
   "source": [
    "<h3 id=\"task-16\">Task 16 (2 points)</h3>\n",
    "Make a prediction of the following <code>x</code> tensor using the linear regression model <code>linear</code>. You must return the value from the <code>lab1_task16</code> function."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 16\n",
    "x = torch.tensor([[1.0],[2.0],[3.0]])\n",
    "def lab1_task16(x):\n",
    "    # Type your code here to return the prediction\n"
   ]
  },
  {
   "source": [
    "<h3 id=\"Cust\">Custom Modules</h3>\n",
    "\n",
    "Now, let's build a custom module. We can make more complex models by using this method later on. \n",
    "\n",
    "First, import the following library."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "source": [
    "Now, let us define the class: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    \"\"\" Customized Linear Regression Class\"\"\"\n",
    "        \n",
    "    def __init__(self, input_size, output_size):\n",
    "        \"\"\"Constuctor\"\"\"  \n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Prediction function\"\"\"\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "source": [
    "Create an object by using the constructor. Print out the parameters we get and the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the linear regression model. Print out the parameters.\n",
    "linear_regression = LinearRegression(1, 1)\n",
    "print(\"The parameters: \", list(linear_regression.parameters()))\n",
    "print(\"Linear model: \", linear_regression.linear)"
   ]
  },
  {
   "source": [
    "Let us try to make a prediction of a single input sample."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try the customized linear regression model with a single input\n",
    "x = torch.tensor([[1.0]])\n",
    "yhat = linear_regression(x)\n",
    "print(\"The prediction: \", yhat)"
   ]
  },
  {
   "source": [
    "Now, let us try another example."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try the customized linear regression model with multiple inputs\n",
    "x = torch.tensor([[1.0], [2.0]])\n",
    "yhat = linear_regression(x)\n",
    "print(\"The prediction: \", yhat)"
   ]
  },
  {
   "source": [
    "<h3 id=\"task-17\">Task 17 (2 points)</h3>\n",
    "\n",
    "Create an object from the <code>LinearRegression</code> class we created before and make a prediction by using the following tensor <code>x</code>. You must return the value from the <code>lab1_task17</code> function. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 17: Use the LinearRegression class to create a model and make a prediction of the following tensor.\n",
    "x = torch.tensor([[1.0], [2.0], [3.0]])\n",
    "def lab1_task17(x):\n",
    "    # Type your code here to return the prediction"
   ]
  },
  {
   "source": [
    "<h2 id=\"lr-1d-training-one-param\">Training One Parameter</h2>\n",
    "<p>In this section, you will train a model with PyTorch by using some data that you will create. The model only has one parameter: the slope.</p>\n",
    "The class <code>PlotDiagram</code> helps us to visualize the data space and the parameter space during training. This class has nothing to do with PyTorch, and is included here as supplemental code for the lab."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotDiagram():\n",
    "    \"\"\"The class for plotting diagrams\"\"\"\n",
    "    \n",
    "    def __init__(self, X, Y, w, stop, go = False):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        start = w.data\n",
    "        self.error = []\n",
    "        self.parameter = []\n",
    "        self.X = X.numpy()\n",
    "        self.Y = Y.numpy()\n",
    "        self.parameter_values = torch.arange(start, stop)\n",
    "        self.Loss_function = [criterion(forward(X), Y) for w.data in self.parameter_values] \n",
    "        w.data = start\n",
    "        \n",
    "    def __call__(self, Yhat, w, error, n):\n",
    "        \"\"\"Executor\"\"\"\n",
    "        self.error.append(error)\n",
    "        self.parameter.append(w.data)\n",
    "        plt.subplot(212)\n",
    "        plt.plot(self.X, Yhat.detach().numpy())\n",
    "        plt.plot(self.X, self.Y,'ro')\n",
    "        plt.xlabel(\"A\")\n",
    "        plt.ylim(-20, 20)\n",
    "        plt.subplot(211)\n",
    "        plt.title(\"Data Space (top) Estimated Line (bottom) Iteration \" + str(n))\n",
    "        plt.plot(self.parameter_values.numpy(), self.Loss_function)   \n",
    "        plt.plot(self.parameter, self.error, 'ro')\n",
    "        plt.xlabel(\"B\")\n",
    "        plt.figure()\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"Destructor\"\"\"\n",
    "        plt.close('all')"
   ]
  },
  {
   "source": [
    "Generate values from -3 to 3 that create a line with a slope of -3. This is the line you will estimate."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the f(X) with a slope of -3\n",
    "X = torch.arange(-3, 3, 0.1).view(-1, 1)\n",
    "f = -3 * X"
   ]
  },
  {
   "source": [
    "Let us plot the line."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the line\n",
    "plt.plot(X.numpy(), f.numpy(), label = 'f')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "Let's add some noise to the data in order to simulate real data. Use <code>torch.randn(X.size())</code> to generate Gaussian noise that is the same size as <code>X</code> and has a standard deviation of 0.1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some noise to f(X) and save it in Y\n",
    "Y = f + 0.1 * torch.randn(X.size())"
   ]
  },
  {
   "source": [
    "Plot the <code>Y</code>: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data points\n",
    "plt.plot(X.numpy(), Y.numpy(), 'rx', label = 'Y')\n",
    "plt.plot(X.numpy(), f.numpy(), label = 'f')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "<h3 id=\"Model_Cost\">Create the Model and Cost Function (Total Loss)</h3>\n",
    "In this section, let us create the model and the cost function (total loss) we are going to use to train the model and evaluate the result.\n",
    "First, let's define the <code>forward_without_bias</code> function $y=w*x$. (We will add the bias soon.)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_without_bias(x):\n",
    "    \"\"\"forward funtion for prediction\"\"\"\n",
    "    return w * x"
   ]
  },
  {
   "source": [
    "Define the cost or criterion function using MSE (Mean Square Error): "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(yhat, y):\n",
    "    \"\"\"Create the MSE (Mean Square Error) function to evaluate the result.\"\"\"\n",
    "    return torch.mean((yhat - y) ** 2)"
   ]
  },
  {
   "source": [
    "Define the learning rate <code>learning_rate</code> and an empty list <code>LOSS</code> to record the loss for each iteration:   "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Learning Rate and an empty list to record the loss for each iteration\n",
    "learning_rate = 0.1\n",
    "LOSS = []"
   ]
  },
  {
   "source": [
    "Now, we create a model parameter by setting the argument <code>requires_grad</code> to <code> True</code> because the system must learn it."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(-10.0, requires_grad = True)"
   ]
  },
  {
   "source": [
    "Create a <code>PlotDiagram</code> object to visualize the data space and the parameter space for each iteration during training:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_plot = PlotDiagram(X, Y, w, stop = 5)"
   ]
  },
  {
   "source": [
    "<h3 id=\"Train\">Train the Model</h3>\n",
    "Let us define a function for training the model. The steps are described in the comments."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(iter):\n",
    "    \"\"\"Function for training the model\"\"\"\n",
    "    for epoch in range (iter):\n",
    "        \n",
    "        # make the prediction\n",
    "        Yhat = forward_without_bias(X)\n",
    "        \n",
    "        # calculate the loss in each iteration\n",
    "        loss = criterion(Yhat,Y)\n",
    "        \n",
    "        # plot the diagram for us to have a better idea\n",
    "        gradient_plot(Yhat, w, loss.item(), epoch)\n",
    "        \n",
    "        # store the loss in the global LOSS list\n",
    "        LOSS.append(loss)\n",
    "        \n",
    "        # backward pass: compute gradient of the loss with respect to all the learnable parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # updata parameters\n",
    "        w.data = w.data - learning_rate * w.grad.data\n",
    "        \n",
    "        # zero the gradients before running the backward pass\n",
    "        w.grad.data.zero_()"
   ]
  },
  {
   "source": [
    "Let us try to run 4 iterations of gradient descent:  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 iterations for training the model.\n",
    "train_model(4)"
   ]
  },
  {
   "source": [
    "Plot the cost for each iteration: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss for each iteration\n",
    "plt.plot(LOSS)\n",
    "plt.tight_layout()\n",
    "plt.xlabel(\"Epoch/Iterations\")\n",
    "plt.ylabel(\"Cost\")"
   ]
  },
  {
   "source": [
    "<h3 id=\"task-18\">Task 18 (3 points)</h3>\n",
    "Create a new learnable parameter <code>w</code> with an initial value of -15.0, and an empty list <code>LOSS2</code>. Then write your own <code>lab1_task18_train_model</code> function with loss list <code>LOSS2</code>. Run your training model with 4 iterations. Plot an overlay of the list <code>LOSS2</code> and <code>LOSS</code>."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 18\n",
    "w = # Type your code here\n",
    "LOSS2 = # Type your code here\n",
    "gradient_plot1 = PlotDiagram(X, Y, w, stop = 15)\n",
    "\n",
    "def lab1_task18_train_model(iter):\n",
    "    # Type your lab02_task04_train_model function definiition here\n",
    "\n",
    "lab1_task18_train_model(4)\n",
    "\n",
    "# Type your code to plot the results using plt"
   ]
  },
  {
   "source": [
    "<h2 id=\"lr-1d-training-two-params\">Training Two Parameters</h2>\n",
    "\n",
    "We'll need the following library for this section."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "source": [
    "The class <code>PlotErrorSurfaces</code> is just to help you visualize the data space and the parameter space during training. This class has nothing to do with PyTorch, and is included here as supplemental code for the lab."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotErrorSurfaces(object):\n",
    "    \n",
    "    def __init__(self, w_range, b_range, X, Y, n_samples = 30, go = True):\n",
    "        W = np.linspace(-w_range, w_range, n_samples)\n",
    "        B = np.linspace(-b_range, b_range, n_samples)\n",
    "        w, b = np.meshgrid(W, B)    \n",
    "        Z = np.zeros((30,30))\n",
    "        count1 = 0\n",
    "        self.y = Y.numpy()\n",
    "        self.x = X.numpy()\n",
    "        for w1, b1 in zip(w, b):\n",
    "            count2 = 0\n",
    "            for w2, b2 in zip(w1, b1):\n",
    "                Z[count1, count2] = np.mean((self.y - w2 * self.x + b2) ** 2)\n",
    "                count2 += 1\n",
    "            count1 += 1\n",
    "        self.Z = Z\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.W = []\n",
    "        self.B = []\n",
    "        self.LOSS = []\n",
    "        self.n = 0\n",
    "        if go == True:\n",
    "            plt.figure()\n",
    "            plt.figure(figsize = (7.5, 5))\n",
    "            plt.axes(projection='3d').plot_surface(self.w, self.b, self.Z, rstride = 1, cstride = 1,cmap = 'viridis', edgecolor = 'none')\n",
    "            plt.title('Cost/Total Loss Surface')\n",
    "            plt.xlabel('w')\n",
    "            plt.ylabel('b')\n",
    "            plt.show()\n",
    "            plt.figure()\n",
    "            plt.title('Cost/Total Loss Surface Contour')\n",
    "            plt.xlabel('w')\n",
    "            plt.ylabel('b')\n",
    "            plt.contour(self.w, self.b, self.Z)\n",
    "            plt.show()\n",
    "    \n",
    "    def set_para_loss(self, W, B, loss):\n",
    "        self.n = self.n + 1\n",
    "        self.W.append(W)\n",
    "        self.B.append(B)\n",
    "        self.LOSS.append(loss)\n",
    "    \n",
    "    def set_para_loss_model(self, model, loss):\n",
    "        self.n = self.n + 1\n",
    "        self.LOSS.append(loss)\n",
    "        self.W.append(list(model.parameters())[0].item())\n",
    "        self.B.append(list(model.parameters())[1].item())\n",
    "\n",
    "    \n",
    "    def final_plot(self): \n",
    "        ax = plt.axes(projection = '3d')\n",
    "        ax.plot_wireframe(self.w, self.b, self.Z)\n",
    "        ax.scatter(self.W,self.B, self.LOSS, c = 'r', marker = 'x', s = 200, alpha = 1)\n",
    "        plt.figure()\n",
    "        plt.contour(self.w,self.b, self.Z)\n",
    "        plt.scatter(self.W, self.B, c = 'r', marker = 'x')\n",
    "        plt.xlabel('w')\n",
    "        plt.ylabel('b')\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_ps(self):\n",
    "        plt.subplot(121)\n",
    "        plt.ylim\n",
    "        plt.plot(self.x, self.y, 'ro', label=\"training points\")\n",
    "        plt.plot(self.x, self.W[-1] * self.x + self.B[-1], label = \"estimated line\")\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.ylim((-10, 15))\n",
    "        plt.title('Data Space Iteration: ' + str(self.n))\n",
    "\n",
    "        plt.subplot(122)\n",
    "        plt.contour(self.w, self.b, self.Z)\n",
    "        plt.scatter(self.W, self.B, c = 'r', marker = 'x')\n",
    "        plt.title('Total Loss Surface Contour Iteration' + str(self.n))\n",
    "        plt.xlabel('w')\n",
    "        plt.ylabel('b')\n",
    "        plt.show()"
   ]
  },
  {
   "source": [
    "<h3 id=\"Makeup_Data\">Make Some Data</h3>\n",
    "Start with generating values from -3 to 3 that create a line with a slope of 1 and a bias of -1. This is the line that you need to estimate."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1-D tensor of size (end-start)/step, where start=-3, end=3, and step=0.1,\n",
    "# with the values from the interval [start, end) taken with common difference step \n",
    "# beginning from start, and then reshape it to create a 2-D tensor.\n",
    "X = torch.arange(-3, 3, 0.1).view(-1, 1)\n",
    "\n",
    "# Create f(X) with a slope of 1 and a bias of -1\n",
    "f = 1 * X - 1"
   ]
  },
  {
   "source": [
    "Now, add some noise to the data:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise\n",
    "Y = f + 0.1 * torch.randn(X.size())"
   ]
  },
  {
   "source": [
    "Plot the line and <code>Y</code> with noise:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the line and the points with noise\n",
    "plt.plot(X.numpy(), Y.numpy(), 'rx', label = 'y')\n",
    "plt.plot(X.numpy(), f.numpy(), label = 'f')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()"
   ]
  },
  {
   "source": [
    "<h3 id=\"Model_Cost\">Create the Model and Cost Function (Total Loss)</h3>\n",
    "Create a <code>PlotErrorSurfaces</code> object to visualize the data space and the parameter space during training:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PlotErrorSurfaces object for viewing the data\n",
    "error_surfaces = PlotErrorSurfaces(15, 15, X, Y, 30)"
   ]
  },
  {
   "source": [
    "<h3 id=\"Train\">Train the Model</h3>\n",
    "\n",
    "Create model parameters <code>w</code>, <code>b</code> by setting the argument <code>requires_grad</code> to True because we must learn it using the data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters w, b for y = wx + b\n",
    "w = torch.tensor(-15.0, requires_grad = True)\n",
    "b = torch.tensor(-10.0, requires_grad = True)"
   ]
  },
  {
   "source": [
    "Set the learning rate to 0.1 and create an empty list <code>loss</code> for storing the loss for each iteration."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define learning rate and create an empty list for containing the loss for each iteration.\n",
    "learning_rate = 0.1\n",
    "LOSS = []"
   ]
  },
  {
   "source": [
    "Define <code>train_model</code> function to train the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(iter):\n",
    "    \n",
    "    # Loop\n",
    "    for epoch in range(iter):\n",
    "        \n",
    "        # make a prediction\n",
    "        Yhat = forward(X)\n",
    "        \n",
    "        # calculate the loss \n",
    "        loss = criterion(Yhat, Y)\n",
    "\n",
    "        # Section for plotting\n",
    "        error_surfaces.set_para_loss(w.data.tolist(), b.data.tolist(), loss.tolist())\n",
    "        if epoch % 3 == 0:\n",
    "            error_surfaces.plot_ps()\n",
    "            \n",
    "        # store the loss in the list LOSS\n",
    "        LOSS.append(loss)\n",
    "        \n",
    "        # backward pass: compute gradient of the loss with respect to all the learnable parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters slope and bias\n",
    "        w.data = w.data - learning_rate * w.grad.data\n",
    "        b.data = b.data - learning_rate * b.grad.data\n",
    "        \n",
    "        # zero the gradients before running the backward pass\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()"
   ]
  },
  {
   "source": [
    "Run 15 iterations of gradient descent."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with 15 iterations\n",
    "train_model(15)"
   ]
  },
  {
   "source": [
    "Plot total loss/cost surface with loss values for different parameters in red:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot out the Loss Result\n",
    "error_surfaces.final_plot()\n",
    "plt.plot(LOSS)\n",
    "plt.tight_layout()\n",
    "plt.xlabel(\"Epoch/Iterations\")\n",
    "plt.ylabel(\"Cost\")"
   ]
  },
  {
   "source": [
    "<h3 id=\"task-19\">Task 19 (4 points)</h3>\n",
    "\n",
    "Using learning rate of 0.2 and with the following parameters, fill in the code for the function <code>lab1_task19_train_model(iter)</code>. As can be seen in the code snippet below, we want to run 15 iterations of your model. Then plot <code>LOSS</code> and <code>LOSS2</code>."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 19: train and plot the result with learning_rate = 0.2 and the following parameters\n",
    "w = torch.tensor(-15.0, requires_grad = True)\n",
    "b = torch.tensor(-10.0, requires_grad = True)\n",
    "learning_rate = 0.2\n",
    "LOSS2 = []\n",
    "\n",
    "def lab1_task19_train_model(iter):\n",
    "    # Type your code here\n",
    "\n",
    "lab1_task19_train_model(15)\n",
    "\n",
    "# Type your code here to plot the LOSS and LOSS2 in order to compare the Total Loss."
   ]
  },
  {
   "source": [
    "<h2 id=\"#lr-1d-training-two-params-sgd\">Stochastic Gradient Descent (SGD)</h2>\n",
    "\n",
    "<p>In this section, you will practice training a model by using Stochastic Gradient descent.</p>\n",
    "\n",
    "<h3 id=\"Makeup_Data\">Make Some Data</h3>\n",
    "Set random seed: \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "source": [
    "Generate values from <i>-3</i> to <i>3</i> that create a line with a slope of <i>1</i> and a bias of <i>-1</i>. This is the line that you need to estimate. Add some noise to the data:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the actual data and simulated data\n",
    "X = torch.arange(-3, 3, 0.1).view(-1, 1)\n",
    "f = 1 * X - 1\n",
    "Y = f + 0.1 * torch.randn(X.size())"
   ]
  },
  {
   "source": [
    "Plot the data:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X.numpy(), Y.numpy(), 'rx', label = 'y')\n",
    "plt.plot(X.numpy(), f.numpy(), label = 'f')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "<h3 id=\"Model_Cost\">Create the Model and Cost Function (Total Loss)</h3>\n",
    "Create a <code> PlotErrorSurfaces</code> object to visualize the data space and the parameter space during training:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_surfaces = PlotErrorSurfaces(15, 13, X, Y, 30)"
   ]
  },
  {
   "source": [
    "<h3 id=\"BGD\">Train the Model: Batch Gradient Descent</h3>\n",
    "Create model parameters <code>w</code>, <code>b</code> by setting the argument <code>requires_grad</code> to True because the system must learn it."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters w, b for y = wx + b\n",
    "w = torch.tensor(-15.0, requires_grad = True)\n",
    "b = torch.tensor(-10.0, requires_grad = True)"
   ]
  },
  {
   "source": [
    "Set the learning rate to  0.1 and create an empty list <code>LOSS</code> for storing the loss for each iteration."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define learning rate and create an empty list for containing the loss for each iteration.\n",
    "learning_rate = 0.1\n",
    "LOSS_BGD = []"
   ]
  },
  {
   "source": [
    "Define <code>train_model</code> function for train the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(iter):\n",
    "    \n",
    "    # Loop\n",
    "    for epoch in range(iter):\n",
    "        \n",
    "        # make a prediction\n",
    "        Yhat = forward(X)\n",
    "        \n",
    "        # calculate the loss \n",
    "        loss = criterion(Yhat, Y)\n",
    "\n",
    "        # Section for plotting\n",
    "        error_surfaces.set_para_loss(w.data.tolist(), b.data.tolist(), loss.tolist())\n",
    "        error_surfaces.plot_ps()\n",
    "            \n",
    "        # store the loss in the list LOSS_BGD\n",
    "        LOSS_BGD.append(loss)\n",
    "        \n",
    "        # backward pass: compute gradient of the loss with respect to all the learnable parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters slope and bias\n",
    "        w.data = w.data - learning_rate * w.grad.data\n",
    "        b.data = b.data - learning_rate * b.grad.data\n",
    "        \n",
    "        # zero the gradients before running the backward pass\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()"
   ]
  },
  {
   "source": [
    "Run 10 epochs of batch gradient descent."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(10)"
   ]
  },
  {
   "source": [
    "<h3 id=\"SGD\">Train the Model: Stochastic Gradient Descent</h3>\n",
    "\n",
    "Create a <code>PlotErrorSurfaces</code> object to visualize the data space and the parameter space during training."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_surfaces = PlotErrorSurfaces(15, 13, X, Y, 30, go = False)"
   ]
  },
  {
   "source": [
    "Define <code>train_model_SGD</code> function for training the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_SGD = []\n",
    "w = torch.tensor(-15.0, requires_grad = True)\n",
    "b = torch.tensor(-10.0, requires_grad = True)\n",
    "\n",
    "def train_model_SGD(iter):\n",
    "    \n",
    "    for epoch in range(iter):\n",
    "        \n",
    "        # SGD is an approximation of out true total loss/cost, in this line of code we calculate our true loss/cost and store it\n",
    "        Yhat = forward(X)\n",
    "\n",
    "        # store the loss \n",
    "        LOSS_SGD.append(criterion(Yhat, Y).tolist())\n",
    "        \n",
    "        for x, y in zip(X, Y):\n",
    "            \n",
    "            # make a pridiction\n",
    "            yhat = forward(x)\n",
    "        \n",
    "            # calculate the loss \n",
    "            loss = criterion(yhat, y)\n",
    "\n",
    "            # Section for plotting\n",
    "            error_surfaces.set_para_loss(w.data.tolist(), b.data.tolist(), loss.tolist())\n",
    "        \n",
    "            # backward pass: compute gradient of the loss with respect to all the learnable parameters\n",
    "            loss.backward()\n",
    "        \n",
    "            # update parameters slope and bias\n",
    "            w.data = w.data - learning_rate * w.grad.data\n",
    "            b.data = b.data - learning_rate * b.grad.data\n",
    "\n",
    "            # zero the gradients before running the backward pass\n",
    "            w.grad.data.zero_()\n",
    "            b.grad.data.zero_()\n",
    "            \n",
    "        #plot surface and data space after each epoch    \n",
    "        error_surfaces.plot_ps()"
   ]
  },
  {
   "source": [
    "Run 10 epochs of stochastic gradient descent."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_SGD(10)"
   ]
  },
  {
   "source": [
    "Compare the losses of Batch Gradient Descent (BGD) and Stochastic Gradient Descent (SGD)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(LOSS_BGD,label = \"Batch Gradient Descent\")\n",
    "plt.plot(LOSS_SGD,label = \"Stochastic Gradient Descent\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Cost/ total loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "<h3 id=\"SGD_Loader\">SGD with Dataset DataLoader</h3>\n",
    "Import the module for building a dataset class."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "source": [
    "Create a custom <code>Data</code> class for loading datasets into the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Constructor\"\"\"\n",
    "        self.x = torch.arange(-3, 3, 0.1).view(-1, 1)\n",
    "        self.y = 1 * self.x - 1\n",
    "        self.len = self.x.shape[0]\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        \"\"\"Getter\"\"\"  \n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Return the length\"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "source": [
    "Create a dataset object and check the length of the dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = Data()\n",
    "print(\"The length of dataset: \", len(my_dataset))"
   ]
  },
  {
   "source": [
    "Obtain the first training point:  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first point\n",
    "x, y = my_dataset[0]\n",
    "print(\"(\", x, \", \", y, \")\")"
   ]
  },
  {
   "source": [
    "Similarly, obtain the first three training points:  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 3 points\n",
    "x, y = my_dataset[0:3]\n",
    "print(\"The first 3 x: \", x)\n",
    "print(\"The first 3 y: \", y)"
   ]
  },
  {
   "source": [
    "Create a <code>PlotErrorSurfaces</code> object to visualize the data space and the parameter space during training:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot_error_surfaces for viewing the data\n",
    "error_surfaces = PlotErrorSurfaces(15, 13, X, Y, 30, go = False)"
   ]
  },
  {
   "source": [
    "Create a <code>DataLoader</code> object."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset = my_dataset, batch_size = 1)"
   ]
  },
  {
   "source": [
    "Define <code>train_model_dataloader</code> function for training the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(-15.0,requires_grad=True)\n",
    "b = torch.tensor(-10.0,requires_grad=True)\n",
    "LOSS_loader = []\n",
    "\n",
    "def train_model_dataloader(epochs):\n",
    "    \n",
    "    # Loop\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # SGD is an approximation of our true total loss/cost, \n",
    "        # in this line of code we calculate our true loss/cost and store it.\n",
    "        Yhat = forward(X)\n",
    "        \n",
    "        # store the loss \n",
    "        LOSS_loader.append(criterion(Yhat, Y).tolist())\n",
    "        \n",
    "        for x, y in trainloader:\n",
    "            \n",
    "            # make a prediction\n",
    "            yhat = forward(x)\n",
    "            \n",
    "            # calculate the loss\n",
    "            loss = criterion(yhat, y)\n",
    "            \n",
    "            # Section for plotting\n",
    "            error_surfaces.set_para_loss(w.data.tolist(), b.data.tolist(), loss.tolist())\n",
    "            \n",
    "            # Backward pass: compute gradient of the loss with respect to all the learnable parameters\n",
    "            loss.backward()\n",
    "            \n",
    "            # Updata parameters slope\n",
    "            w.data = w.data - learning_rate * w.grad.data\n",
    "            b.data = b.data - learning_rate * b.grad.data\n",
    "            \n",
    "            # Clear gradients \n",
    "            w.grad.data.zero_()\n",
    "            b.grad.data.zero_()\n",
    "            \n",
    "        #plot surface and data space after each epoch    \n",
    "        error_surfaces.plot_ps()"
   ]
  },
  {
   "source": [
    "Run 10 epochs of stochastic gradient descent with <code>train_model_dataloader</code>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_dataloader(10)"
   ]
  },
  {
   "source": [
    "Compare the loss of both batch gradient decent as SGD. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(LOSS_BGD,label=\"Batch Gradient Descent\")\n",
    "plt.plot(LOSS_loader,label=\"Stochastic Gradient Descent with DataLoader\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Cost/ total loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "<h3 id=\"task-20\">Task 20 (5 points)</h3>\n",
    "Use SGD with DataLoader to train the model with 10 iterations. Please complete the <code>lab1_task20_train_model(epochs)</code>. Use <code>LOSS</code> to store the total loss, and plot the total loss."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 20\n",
    "LOSS = []\n",
    "w = torch.tensor(-12.0, requires_grad = True)\n",
    "b = torch.tensor(-10.0, requires_grad = True)\n",
    "\n",
    "def lab1_task20_train_model(epochs):\n",
    "    # Type your code here\n",
    "\n",
    "lab1_task20_train_model(10)\n",
    "\n",
    "# Type your code here to plot the LOSS.\n"
   ]
  },
  {
   "source": [
    "<h2 id=\"lr-1d-two-params-mbgd\">Mini-Batch Gradient Decent</h2>\n",
    "\n",
    "<p>In this section, you will practice training a model by using Mini-Batch Gradient Descent.</p>\n",
    "<h3 id=\"Makeup_Data\">Make Some Data </h3>\n",
    "Generate values from -3 to 3 that create a line with a slope of 1 and a bias of -1. This is the line that you need to estimate. Add some noise to the data and plot the results. Then create a <code> PlotErrorSurfaces</code> object to visualize the data space and the parameter space during training.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "X = torch.arange(-3, 3, 0.1).view(-1, 1)\n",
    "f = 1 * X - 1\n",
    "Y = f + 0.1 * torch.randn(X.size())\n",
    "\n",
    "plt.plot(X.numpy(), Y.numpy(), 'rx', label = 'y')\n",
    "plt.plot(X.numpy(), f.numpy(), label = 'f')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Initialize error surfaces\n",
    "error_surfaces = PlotErrorSurfaces(15, 13, X, Y, 30)"
   ]
  },
  {
   "source": [
    "<h3>Train the Model: Batch Gradient Descent (BGD)</h3>\n",
    "Define <code>train_model_BGD</code> function, and run 10 epochs of batch gradient descent."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function for training model\n",
    "w = torch.tensor(-15.0, requires_grad = True)\n",
    "b = torch.tensor(-10.0, requires_grad = True)\n",
    "learning_rate = 0.1\n",
    "LOSS_BGD = []\n",
    "\n",
    "def train_model_BGD(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        Yhat = forward(X)\n",
    "        loss = criterion(Yhat, Y)\n",
    "        LOSS_BGD.append(loss)\n",
    "        error_surfaces.set_para_loss(w.data.tolist(), b.data.tolist(), loss.tolist())\n",
    "        error_surfaces.plot_ps()\n",
    "        loss.backward()\n",
    "        w.data = w.data - learning_rate * w.grad.data\n",
    "        b.data = b.data - learning_rate * b.grad.data\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "\n",
    "# Run train_model_BGD with 10 iterations\n",
    "train_model_BGD(10)"
   ]
  },
  {
   "source": [
    "<h3 id=\"SGD\"> Stochastic Gradient Descent (SGD) with Dataset DataLoader</h3>\n",
    "Import <code>Dataset</code> and <code>DataLoader</code> libraries and create a dataset object and a dataloader object: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "my_dataset = Data()\n",
    "trainloader = DataLoader(dataset = my_dataset, batch_size = 1)\n",
    "\n",
    "#Initialize error surfaces\n",
    "error_surfaces = PlotErrorSurfaces(15, 13, X, Y, 30)"
   ]
  },
  {
   "source": [
    "Define <code>train_model_SGD</code> function for training the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(-15.0, requires_grad = True)\n",
    "b = torch.tensor(-10.0, requires_grad = True)\n",
    "LOSS_SGD = []\n",
    "learning_rate = 0.1\n",
    "def train_model_SGD(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        Yhat = forward(X)\n",
    "        error_surfaces.set_para_loss(w.data.tolist(), b.data.tolist(), criterion(Yhat, Y).tolist())\n",
    "        error_surfaces.plot_ps()\n",
    "        LOSS_SGD.append(criterion(forward(X), Y).tolist())\n",
    "        for x, y in trainloader:\n",
    "            yhat = forward(x)\n",
    "            loss = criterion(yhat, y)\n",
    "            error_surfaces.set_para_loss(w.data.tolist(), b.data.tolist(), loss.tolist())\n",
    "            loss.backward()\n",
    "            w.data = w.data - learning_rate * w.grad.data\n",
    "            b.data = b.data - learning_rate * b.grad.data\n",
    "            w.grad.data.zero_()\n",
    "            b.grad.data.zero_()\n",
    "        error_surfaces.plot_ps()"
   ]
  },
  {
   "source": [
    "Run 10 epochs of stochastic gradient descent: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run train_model_SGD(iter) with 10 iterations\n",
    "train_model_SGD(10)"
   ]
  },
  {
   "source": [
    "<h3 id=\"Mini5\">Mini Batch Gradient Descent: Batch Size Equals 5</h3> \n",
    "\n",
    "Create a <code> PlotErrorSurfaces</code> object to visualize the data space and the parameter space during training, and create <code>Data</code> object and create a <code>Dataloader</code> object batch size equals 5."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader object\n",
    "my_dataset = Data()\n",
    "trainloader = DataLoader(dataset = my_dataset, batch_size = 5)\n",
    "\n",
    "#Initialize error surfaces\n",
    "error_surfaces = PlotErrorSurfaces(15, 13, X, Y, 30, go = False)"
   ]
  },
  {
   "source": [
    "Define <code>train_model_Mini5</code> function to train the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(-15.0, requires_grad = True)\n",
    "b = torch.tensor(-10.0, requires_grad = True)\n",
    "LOSS_MINI5 = []\n",
    "learning_rate = 0.1\n",
    "\n",
    "def train_model_Mini5(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        Yhat = forward(X)\n",
    "        error_surfaces.set_para_loss(w.data.tolist(), b.data.tolist(), criterion(Yhat, Y).tolist())\n",
    "        error_surfaces.plot_ps()\n",
    "        LOSS_MINI5.append(criterion(forward(X), Y).tolist())\n",
    "        for x, y in trainloader:\n",
    "            yhat = forward(x)\n",
    "            loss = criterion(yhat, y)\n",
    "            error_surfaces.set_para_loss(w.data.tolist(), b.data.tolist(), loss.tolist())\n",
    "            loss.backward()\n",
    "            w.data = w.data - learning_rate * w.grad.data\n",
    "            b.data = b.data - learning_rate * b.grad.data\n",
    "            w.grad.data.zero_()\n",
    "            b.grad.data.zero_()"
   ]
  },
  {
   "source": [
    "Run 10 epochs of mini-batch gradient descent: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_Mini5(10)"
   ]
  },
  {
   "source": [
    "<h3 id=\"Mini10\">Mini Batch Gradient Descent: Batch Size Equals 10</h3> \n",
    "Create a <code> PlotErrorSurfaces</code> object to visualize the data space and the parameter space during training, and create <code>Data</code> object and create a <code>Dataloader</code> object batch size equals 10."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader object\n",
    "my_dataset = Data()\n",
    "trainloader = DataLoader(dataset = my_dataset, batch_size = 10)\n",
    "\n",
    "#Initialize error surfaces\n",
    "error_surfaces = PlotErrorSurfaces(15, 13, X, Y, 30)"
   ]
  },
  {
   "source": [
    "Define <code>train_model_mini10</code> function for training the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train_model_mini10 function\n",
    "w = torch.tensor(-15.0, requires_grad = True)\n",
    "b = torch.tensor(-10.0, requires_grad = True)\n",
    "LOSS_MINI10 = []\n",
    "learning_rate = 0.1\n",
    "\n",
    "def train_model_Mini10(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        Yhat = forward(X)\n",
    "        error_surfaces.set_para_loss(w.data.tolist(), b.data.tolist(), criterion(Yhat, Y).tolist())\n",
    "        error_surfaces.plot_ps()\n",
    "        LOSS_MINI10.append(criterion(forward(X),Y).tolist())\n",
    "        for x, y in trainloader:\n",
    "            yhat = forward(x)\n",
    "            loss = criterion(yhat, y)\n",
    "            error_surfaces.set_para_loss(w.data.tolist(), b.data.tolist(), loss.tolist())\n",
    "            loss.backward()\n",
    "            w.data = w.data - learning_rate * w.grad.data\n",
    "            b.data = b.data - learning_rate * b.grad.data\n",
    "            w.grad.data.zero_()\n",
    "            b.grad.data.zero_()"
   ]
  },
  {
   "source": [
    "Run 10 epochs of mini-batch gradient descent and plot the loss for each epoch."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_Mini10(10)"
   ]
  },
  {
   "source": [
    "Plot the loss for each epoch:  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(LOSS_BGD,label = \"Batch Gradient Descent\")\n",
    "plt.plot(LOSS_SGD,label = \"Stochastic Gradient Descent\")\n",
    "plt.plot(LOSS_MINI5,label = \"Mini-Batch Gradient Descent, Batch size: 5\")\n",
    "plt.plot(LOSS_MINI10,label = \"Mini-Batch Gradient Descent, Batch size: 10\")\n",
    "plt.legend()"
   ]
  },
  {
   "source": [
    "<h3 id=\"task-21\">Task 21 (5 points)</h3>\n",
    "\n",
    "Perform mini batch gradient descent with a batch size of 20. Store the total loss for each epoch in the list LOSS20. Please complete the <code>lab1_task21_train_model(epochs)</code>. Use <code>LOSS20</code> to store the total loss, and plot a graph that shows the LOSS results for all the methods (i.e., batch gradient descent, stochastic gradient descent, batch size = 5,10, and 20).\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 21\n",
    "my_dataset = Data()\n",
    "LOSS20 = []\n",
    "w = torch.tensor(-15.0, requires_grad = True)\n",
    "b = torch.tensor(-10.0, requires_grad = True)\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Type your code here to define the trainloader\n",
    "\n",
    "def lab1_task21_train_model(epochs):\n",
    "    # Type your code here\n",
    "\n",
    "lab1_task21_train_model(10)\n",
    "\n",
    "# Type your code here to plot the LOSS."
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}